{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "471b0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "csv_files = glob.glob('weekly_county2county_2019_01_*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2d2f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weekly_county2county_2019_01_07.csv',\n",
       " 'weekly_county2county_2019_01_14.csv',\n",
       " 'weekly_county2county_2019_01_21.csv',\n",
       " 'weekly_county2county_2019_01_28.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013354fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d18b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         geoid_o  geoid_d       lng_o      lat_o       lng_d      lat_d  \\\n",
       "0          1001     1001  -86.642757  32.534921  -86.642757  32.534921   \n",
       "1          1001     1003  -86.642757  32.534921  -87.749845  30.660974   \n",
       "2          1001     1005  -86.642757  32.534921  -85.393197  31.869603   \n",
       "3          1001     1007  -86.642757  32.534921  -87.126439  32.998644   \n",
       "4          1001     1011  -86.642757  32.534921  -85.715697  32.100554   \n",
       "...         ...      ...         ...        ...         ...        ...   \n",
       "478526    30051    30071 -111.024580  48.561755 -107.913236  48.259182   \n",
       "478527    30051    30051 -111.024580  48.561755 -111.024580  48.561755   \n",
       "478528     2230     2170 -135.337793  59.558522 -149.578978  62.304529   \n",
       "478529     2230     2100 -135.337793  59.558522 -135.472590  59.073878   \n",
       "478530     2230     2230 -135.337793  59.558522 -135.337793  59.558522   \n",
       "\n",
       "                 date_range  visitor_flows  pop_flows  \n",
       "0       01/14/19 - 01/20/19          14651   200129.0  \n",
       "1       01/14/19 - 01/20/19             59      805.0  \n",
       "2       01/14/19 - 01/20/19             14      191.0  \n",
       "3       01/14/19 - 01/20/19              8      109.0  \n",
       "4       01/14/19 - 01/20/19              4       54.0  \n",
       "...                     ...            ...        ...  \n",
       "478526  01/14/19 - 01/20/19              4      143.0  \n",
       "478527  01/14/19 - 01/20/19            173     6195.0  \n",
       "478528  01/14/19 - 01/20/19              4      104.0  \n",
       "478529  01/14/19 - 01/20/19              4      104.0  \n",
       "478530  01/14/19 - 01/20/19            102     2652.0  \n",
       "\n",
       "[478531 rows x 9 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f16357bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae96528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd3c5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON template\n",
    "with open(\"template_flow.json\") as f:\n",
    "    template = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6c6700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekly_county2county_2019_01_*.csv\n",
      "['weekly_county2county_2019_01_07.csv', 'weekly_county2county_2019_01_14.csv', 'weekly_county2county_2019_01_21.csv', 'weekly_county2county_2019_01_28.csv']\n",
      "     geoid_o  geoid_d      lng_o      lat_o      lng_d      lat_d  \\\n",
      "0       1001     1001 -86.642757  32.534921 -86.642757  32.534921   \n",
      "1       1001     1003 -86.642757  32.534921 -87.749845  30.660974   \n",
      "2       1001     1005 -86.642757  32.534921 -85.393197  31.869603   \n",
      "3       1001     1009 -86.642757  32.534921 -86.567371  33.980867   \n",
      "4       1001     1013 -86.642757  32.534921 -86.680289  31.752434   \n",
      "..       ...      ...        ...        ...        ...        ...   \n",
      "189     1001    51191 -86.642757  32.534921 -81.959661  36.724479   \n",
      "190     1001    51770 -86.642757  32.534921 -79.958084  37.278408   \n",
      "191     1001    55057 -86.642757  32.534921 -90.113792  43.924605   \n",
      "192     1001    55079 -86.642757  32.534921 -87.580557  43.015458   \n",
      "193     1001    72027 -86.642757  32.534921 -66.862635  18.443077   \n",
      "\n",
      "              date_range  visitor_flows  pop_flows  \n",
      "0    01/07/19 - 01/13/19          14079   190660.0  \n",
      "1    01/07/19 - 01/13/19             60      812.0  \n",
      "2    01/07/19 - 01/13/19             17      230.0  \n",
      "3    01/07/19 - 01/13/19             26      352.0  \n",
      "4    01/07/19 - 01/13/19             28      379.0  \n",
      "..                   ...            ...        ...  \n",
      "189  01/07/19 - 01/13/19              4       54.0  \n",
      "190  01/07/19 - 01/13/19              4       54.0  \n",
      "191  01/07/19 - 01/13/19              4       54.0  \n",
      "192  01/07/19 - 01/13/19              4       54.0  \n",
      "193  01/07/19 - 01/13/19              4       54.0  \n",
      "\n",
      "[194 rows x 9 columns]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " sum1 ^\n",
      "0    190660.0\n",
      "Name: pop_flows, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " y ^\n",
      "463702.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " sum1 ^\n",
      "292757.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " sum2 ^\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " flow ^ \n",
      "463702.0\n"
     ]
    }
   ],
   "source": [
    "for month in range(1,10):\n",
    "    f = 'weekly_county2county_2019_0'+str(month)+'_*.csv'\n",
    "    print(f)\n",
    "    csv_files = glob.glob(f)\n",
    "    print(csv_files)\n",
    "    df_sum1 = 0\n",
    "    df_sum2 = 0\n",
    "\n",
    "\n",
    "    for week in range(len(csv_files)):\n",
    "            name = str(month)+\"_\"+str(week)\n",
    "            #globals()[name]=\n",
    "            df = pd.read_csv(csv_files[week])\n",
    "            \n",
    "            for index, row in df.iterrows():\n",
    "                # access each column value of the current row\n",
    "                geoid_o = row['geoid_o']\n",
    "                geoid_d = row['geoid_d']\n",
    "                date_range = row['date_range']\n",
    "                visitor_flows = row['visitor_flows']\n",
    "                pop_flows = row['pop_flows']\n",
    "                for template_dict in template:\n",
    "                    # find the corresponding row in df_month based on the 'fips' value\n",
    "                    fips_value = template_dict['fips']\n",
    "                    df_sum1 =  df.loc[df['geoid_o'] == fips_value]\n",
    "                    print(df_sum1)\n",
    "                    print(\"\\n\\n\\n\\n sum1 ^\")\n",
    "                    filtered_df = df.loc[(df['geoid_o'] == user_fips_code) & (df['geoid_d'] == user_fips_code)]\n",
    "                    y=df_sum1.loc[df_sum1['geoid_d'] == fips_value][\"pop_flows\"]\n",
    "                    print(y)\n",
    "                    print(\"\\n\\n\\n\\n y ^\")                \n",
    "                    df_sum1 = df_sum1[\"pop_flows\"].sum()\n",
    "                    #print(df_sum1)\n",
    "                    df_sum2 =  df.loc[df['geoid_d'] == fips_value][\"pop_flows\"].sum()\n",
    "                    print(df_sum1)\n",
    "                    print(\"\\n\\n\\n\\n sum1 ^\")\n",
    "                    print(df_sum2)\n",
    "                    print(\"\\n\\n\\n\\n sum2 ^\")                \n",
    "                    #print(df_sum2)\n",
    "                    #print(county_row)\n",
    "                    '''\n",
    "                    x = df.loc[(df['geoid_o'] == fips_value) ]\n",
    "                    y=x.loc[x['geoid_d'] == fips_value]\n",
    "                    print(y)\n",
    "                    print(\"\\n\\n\\n\\n\")\n",
    "                    '''\n",
    "                    #print(df.loc[df['geoid_d'] == fips_value ])\n",
    "                    # update the 'cases' value in the dictionary with the final cumulative value of cases for that county\n",
    "                    print(template_dict['flow'])\n",
    "                    print(\"\\n\\n\\n\\n flow ^ \")                \n",
    "                    template_dict['flow'] =   df_sum1\n",
    "                    print(template_dict['flow'])\n",
    "                    break\n",
    "                break\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ccc5f63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekly_county2county_2020_10_*.csv\n",
      "['weekly_county2county_2020_10_05.csv', 'weekly_county2county_2020_10_12.csv', 'weekly_county2county_2020_10_19.csv', 'weekly_county2county_2020_10_26.csv']\n",
      "out of loop\n",
      "file saved\n",
      "weekly_county2county_2020_11_*.csv\n",
      "['weekly_county2county_2020_11_02.csv', 'weekly_county2county_2020_11_09.csv', 'weekly_county2county_2020_11_16.csv', 'weekly_county2county_2020_11_23.csv', 'weekly_county2county_2020_11_30.csv']\n",
      "out of loop\n",
      "file saved\n",
      "weekly_county2county_2020_12_*.csv\n",
      "['weekly_county2county_2020_12_07.csv', 'weekly_county2county_2020_12_14.csv', 'weekly_county2county_2020_12_21.csv', 'weekly_county2county_2020_12_28.csv']\n",
      "out of loop\n",
      "file saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for month in range(10,13):\n",
    "    f = 'weekly_county2county_2020_'+str(month)+'_*.csv'\n",
    "    print(f)\n",
    "    csv_files = glob.glob(f)\n",
    "    print(csv_files)\n",
    "    df_sum1 = 0\n",
    "    df_sum2 = 0\n",
    "\n",
    "    with open(\"template_flow.json\") as f:\n",
    "        template = json.load(f)\n",
    "    \n",
    "    for week in range(len(csv_files)):\n",
    "        name = str(month)+\"_\"+str(week)\n",
    "        #globals()[name]=\n",
    "        df = pd.read_csv(csv_files[week])\n",
    "        for template_dict in template:\n",
    "            # find the corresponding row in df_month based on the 'fips' value\n",
    "                fips_value = template_dict['fips']\n",
    "                df_sum1 =  df.loc[df['geoid_o'] == fips_value]\n",
    "\n",
    "                #y = y.iloc[-1]\n",
    "                #print(\"y   :\",y.iloc[-1])\n",
    "                df_sum1 = df_sum1[\"pop_flows\"].sum()\n",
    "                \n",
    "                #print(\"sum1   :\",df_sum1)\n",
    "                \n",
    "                df_sum2 =  df.loc[df['geoid_d'] == fips_value][\"pop_flows\"].sum()\n",
    "                \n",
    "                #print(\"sum2   :\",df_sum2)\n",
    "\n",
    "\n",
    "                y = df.loc[(df['geoid_o'] == fips_value) & (df['geoid_d'] == fips_value)][\"pop_flows\"]\n",
    "                if len(y) == 0 :\n",
    "                    \n",
    "                    template_dict['flow'] =  template_dict['flow'] +  df_sum1 + df_sum2\n",
    "                else:\n",
    "                    \n",
    "                    template_dict['flow'] =  template_dict['flow'] +   df_sum1 + df_sum2 - 2*y.iloc[-1]\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                print(\"net    :\",df_sum1 + df_sum2 - 2*y.iloc[-1])\n",
    "                \n",
    "\n",
    "\n",
    "                template_dict['flow'] =   df_sum1 + df_sum2 - 2*y.iloc[-1]\n",
    "                \n",
    "                \n",
    "                #print(y)\n",
    "                #print(\"\\n\\n\\n\\n y ^\")                 \n",
    "                #print(df_sum1)\n",
    "                #print(\"\\n\\n\\n\\n sum1 ^\")\n",
    "                #print(df_sum2)\n",
    "                #print(\"\\n\\n\\n\\n sum2 ^\")                \n",
    "                #print(df_sum2)\n",
    "                #print(county_row)\n",
    "                \n",
    "                \n",
    "                x = df.loc[(df['geoid_o'] == fips_value) ]\n",
    "                y=x.loc[x['geoid_d'] == fips_value]\n",
    "                print(y)\n",
    "                print(\"\\n\\n\\n\\n\")\n",
    "                \n",
    "                #print(df.loc[df['geoid_d'] == fips_value ])\n",
    "                # update the 'cases' value in the dictionary with the final cumulative value of cases for that county\n",
    "                print(template_dict['flow'])\n",
    "                print(\"\\n\\n\\n\\n flow ^ \")                \n",
    "\n",
    "                print(template_dict['flow'])\n",
    "                '''\n",
    "                if (template_dict['flow'] <0):\n",
    "                    print(\"error\")\n",
    "                '''\n",
    "                #template_dict['cases'] = int(template_dict['cases'])\n",
    "                #template_dict['fips'] = int(template_dict['fips'])\n",
    "                print()\n",
    "                '''\n",
    "    print(\"out of loop\")\n",
    "    f = \"2020_\" + str(month) + \".json\"\n",
    "    json_file = open(\"Month_data\\\\\" + f, 'w')\n",
    "    json.dump(template, json_file)\n",
    "    print(\"file saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9082940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weekly_county2county_2019_01_*.csv\n",
      "['weekly_county2county_2019_01_07.csv', 'weekly_county2county_2019_01_14.csv', 'weekly_county2county_2019_01_21.csv', 'weekly_county2county_2019_01_28.csv']\n",
      "463702.0\n",
      "292757.0\n",
      "756459.0\n",
      "492875.0\n",
      "308578.0\n",
      "1557912.0\n",
      "524540.0\n",
      "327054.0\n",
      "2409506.0\n",
      "523052.0\n",
      "339867.0\n",
      "3272425.0\n"
     ]
    }
   ],
   "source": [
    "f = 'weekly_county2county_2020_0'+str(1)+'_*.csv'\n",
    "print(f)\n",
    "csv_files = glob.glob(f)\n",
    "print(csv_files)\n",
    "df_sum1 = 0\n",
    "df_sum2 = 0\n",
    "sum = 0\n",
    "for week in range(len(csv_files)):\n",
    "    name = str(month)+\"_\"+str(week)\n",
    "    #globals()[name]=\n",
    "    df = pd.read_csv(csv_files[week])\n",
    "    for template_dict in template:\n",
    "        # find the corresponding row in df_month based on the 'fips' value\n",
    "        fips_value = template_dict['fips']\n",
    "        df_sum1 =  df.loc[df['geoid_o'] == fips_value][\"pop_flows\"].sum() \n",
    "        df_sum2 =  df.loc[df['geoid_d'] == fips_value][\"pop_flows\"].sum()\n",
    "        \n",
    "        print(df_sum1)\n",
    "        print(df_sum2)\n",
    "        sum = sum + df_sum1 + df_sum2 \n",
    "        break\n",
    "    print(sum) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05876bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
